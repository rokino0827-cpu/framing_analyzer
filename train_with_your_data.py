#!/usr/bin/env python3
"""
ä½¿ç”¨ç°æœ‰æœºå™¨æ ‡æ³¨æ•°æ®è®­ç»ƒSV2000æ¨¡å‹
ä¸“é—¨é’ˆå¯¹ç”¨æˆ·çš„stratified_validation_sample_by_frame_avg.csvæ•°æ®
"""

import os
import sys
import argparse
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ä½¿ç”¨ç°æœ‰æ•°æ®è®­ç»ƒSV2000æ¨¡å‹")
    
    # æ•°æ®è·¯å¾„
    parser.add_argument("--data_path", type=str, 
                       default="data/filtered_labels_with_average.csv",
                       help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--work_dir", type=str, default="./sv2000_training_results",
                       help="å·¥ä½œç›®å½•")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--epochs", type=int, default=15,
                       help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch_size", type=int, default=16,
                       help="æ‰¹å¤„ç†å¤§å°")
    parser.add_argument("--learning_rate", type=float, default=2e-5,
                       help="å­¦ä¹ ç‡")
    parser.add_argument("--device", type=str, default="auto",
                       help="è®¡ç®—è®¾å¤‡")
    
    # æµç¨‹æ§åˆ¶
    parser.add_argument("--skip_validation", action="store_true",
                       help="è·³è¿‡æ•°æ®éªŒè¯")
    parser.add_argument("--skip_training", action="store_true",
                       help="è·³è¿‡æ¨¡å‹è®­ç»ƒ")
    parser.add_argument("--skip_optimization", action="store_true",
                       help="è·³è¿‡æƒé‡ä¼˜åŒ–")
    
    # å…¶ä»–å‚æ•°
    parser.add_argument("--verbose", action="store_true",
                       help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # åˆ›å»ºå·¥ä½œç›®å½•
    os.makedirs(args.work_dir, exist_ok=True)
    
    logger.info("=" * 80)
    logger.info("ä½¿ç”¨ç°æœ‰æœºå™¨æ ‡æ³¨æ•°æ®è®­ç»ƒSV2000æ¨¡å‹")
    logger.info("=" * 80)
    logger.info(f"æ•°æ®è·¯å¾„: {args.data_path}")
    logger.info(f"å·¥ä½œç›®å½•: {args.work_dir}")
    
    try:
        adapted_data_path = args.data_path
        
        # æ­¥éª¤1: æ•°æ®éªŒè¯å’Œé€‚é…
        if not args.skip_validation:
            logger.info("\næ­¥éª¤ 1: æ•°æ®éªŒè¯å’Œé€‚é…")
            logger.info("-" * 50)
            
            from framing_analyzer.validate_existing_data import main as validate_main
            
            # é¦–å…ˆæ£€æŸ¥æ•°æ®ç»“æ„
            validate_args = [
                "--input_path", args.data_path,
                "--inspect_only"
            ]
            
            if args.verbose:
                validate_args.append("--verbose")
            
            # ä¸´æ—¶æ›¿æ¢sys.argvè¿›è¡Œæ£€æŸ¥
            original_argv = sys.argv
            sys.argv = ["validate_existing_data.py"] + validate_args
            
            try:
                validate_main()
            except SystemExit:
                pass  # å¿½ç•¥æ­£å¸¸é€€å‡º
            finally:
                sys.argv = original_argv
            
            # è¯¢é—®ç”¨æˆ·æ˜¯å¦éœ€è¦é€‚é…æ•°æ®
            print("\n" + "=" * 60)
            print("æ•°æ®æ£€æŸ¥å®Œæˆï¼")
            print("è¯·æŸ¥çœ‹ä¸Šé¢çš„æ£€æŸ¥æŠ¥å‘Šï¼Œç¡®è®¤æ•°æ®æ ¼å¼æ˜¯å¦ç¬¦åˆSV2000è®­ç»ƒè¦æ±‚ã€‚")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç”¨æˆ·çš„æœºå™¨æ ‡æ³¨æ ¼å¼
            user_format_detected = False
            try:
                df_check = pd.read_csv(args.data_path)
                user_format_detected = ('sv_frame_avg' in df_check.columns and 
                                      any('sv_' in col and '_q' in col for col in df_check.columns))
            except:
                pass
            
            if user_format_detected:
                print("\nâœ… æ£€æµ‹åˆ°æ‚¨çš„æœºå™¨æ ‡æ³¨æ•°æ®æ ¼å¼ï¼")
                print("ç³»ç»Ÿå°†è‡ªåŠ¨å¤„ç†æ‚¨çš„è¯¦ç»†é—®é¢˜çº§åˆ«åˆ—å¹¶è®¡ç®—æ¡†æ¶åˆ†æ•°ã€‚")
                need_adaptation = 'n'  # ä¸éœ€è¦é¢å¤–é€‚é…
            else:
                print("\nå¦‚æœæ•°æ®æ ¼å¼ä¸ç¬¦åˆè¦æ±‚ï¼Œæˆ‘ä»¬å¯ä»¥è‡ªåŠ¨é€‚é…æ•°æ®æ ¼å¼ã€‚")
                need_adaptation = input("æ˜¯å¦éœ€è¦é€‚é…æ•°æ®æ ¼å¼ï¼Ÿ(y/N): ").strip().lower()
            
            if need_adaptation in ['y', 'yes', 'æ˜¯']:
                logger.info("å¼€å§‹è‡ªåŠ¨é€‚é…æ•°æ®æ ¼å¼...")
                
                adapted_data_path = os.path.join(args.work_dir, "adapted_training_data.csv")
                
                adapt_args = [
                    "--input_path", args.data_path,
                    "--output_path", adapted_data_path,
                    "--auto_adapt"
                ]
                
                if args.verbose:
                    adapt_args.append("--verbose")
                
                # ä¸´æ—¶æ›¿æ¢sys.argvè¿›è¡Œé€‚é…
                sys.argv = ["validate_existing_data.py"] + adapt_args
                
                try:
                    validate_main()
                    logger.info(f"æ•°æ®é€‚é…å®Œæˆ: {adapted_data_path}")
                except SystemExit:
                    pass
                finally:
                    sys.argv = original_argv
            else:
                logger.info("ä½¿ç”¨åŸå§‹æ•°æ®æ ¼å¼è¿›è¡Œè®­ç»ƒ")
        
        # æ­¥éª¤2: æ¨¡å‹è®­ç»ƒ
        if not args.skip_training:
            logger.info("\næ­¥éª¤ 2: SV2000æ¨¡å‹è®­ç»ƒ")
            logger.info("-" * 50)
            
            from framing_analyzer.train_sv2000_model import main as train_main
            
            model_output_dir = os.path.join(args.work_dir, "models")
            
            train_args = [
                "--data_path", adapted_data_path,
                "--output_dir", model_output_dir,
                "--epochs", str(args.epochs),
                "--batch_size", str(args.batch_size),
                "--learning_rate", str(args.learning_rate),
                "--device", args.device,
                "--optimize_weights",
                "--evaluate"
            ]
            
            if args.verbose:
                train_args.append("--verbose")
            
            # ä¸´æ—¶æ›¿æ¢sys.argvè¿›è¡Œè®­ç»ƒ
            sys.argv = ["train_sv2000_model.py"] + train_args
            
            try:
                train_main()
                logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
            except SystemExit:
                pass
            finally:
                sys.argv = original_argv
        
        # æ­¥éª¤3: æƒé‡ä¼˜åŒ–
        if not args.skip_optimization:
            logger.info("\næ­¥éª¤ 3: èåˆæƒé‡ä¼˜åŒ–")
            logger.info("-" * 50)
            
            from framing_analyzer.optimize_fusion_weights import main as optimize_main
            
            optimization_output_dir = os.path.join(args.work_dir, "optimization")
            
            optimize_args = [
                "--data_path", adapted_data_path,
                "--output_dir", optimization_output_dir,
                "--max_samples", "1000"  # é™åˆ¶æ ·æœ¬æ•°ä»¥åŠ é€Ÿ
            ]
            
            if args.verbose:
                optimize_args.append("--verbose")
            
            # ä¸´æ—¶æ›¿æ¢sys.argvè¿›è¡Œä¼˜åŒ–
            sys.argv = ["optimize_fusion_weights.py"] + optimize_args
            
            try:
                optimize_main()
                logger.info("æƒé‡ä¼˜åŒ–å®Œæˆï¼")
            except SystemExit:
                pass
            finally:
                sys.argv = original_argv
        
        # æ­¥éª¤4: ç³»ç»Ÿæµ‹è¯•
        logger.info("\næ­¥éª¤ 4: ç³»ç»Ÿæµ‹è¯•")
        logger.info("-" * 50)
        
        from framing_analyzer import FramingAnalyzer
        from framing_analyzer.config import create_sv2000_config
        
        # åˆ›å»ºé…ç½®
        config = create_sv2000_config()
        
        # é…ç½®è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
        model_path = os.path.join(args.work_dir, "models", "best_sv2000_model.pt")
        if os.path.exists(model_path):
            config.sv_framing.pretrained_model_path = model_path
            logger.info(f"ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹: {model_path}")
        else:
            logger.info("ä½¿ç”¨é»˜è®¤é…ç½®è¿›è¡Œæµ‹è¯•")
        
        # æµ‹è¯•æ–‡ç« 
        test_articles = [
            {
                'content': '''
                The escalating trade war between the two economic superpowers has 
                created uncertainty in global markets. Economists warn that the 
                ongoing tariff disputes could lead to a significant slowdown in 
                international commerce and affect millions of jobs worldwide.
                ''',
                'title': 'Trade War Threatens Global Economic Stability',
                'id': 'test_1'
            },
            {
                'content': '''
                Local residents have come together to rebuild their community center 
                after it was destroyed in last month\'s storm. Volunteers from 
                neighboring towns have donated materials and labor, showing the 
                power of human solidarity in times of crisis.
                ''',
                'title': 'Community Rebuilds After Storm Damage',
                'id': 'test_2'
            }
        ]
        
        try:
            # åˆå§‹åŒ–åˆ†æå™¨
            analyzer = FramingAnalyzer(config)
            
            # æµ‹è¯•åˆ†æ
            logger.info("è¿è¡Œæµ‹è¯•åˆ†æ...")
            results = analyzer.analyze_batch(test_articles)
            
            # æ˜¾ç¤ºç»“æœ
            logger.info("æµ‹è¯•ç»“æœ:")
            for result in results['results']:
                if not result.get('error'):
                    logger.info(f"  æ–‡ç« : {result['title']}")
                    logger.info(f"    å¼ºåº¦: {result['framing_intensity']:.3f}")
                    logger.info(f"    æ ‡ç­¾: {result['pseudo_label']}")
                    
                    if 'sv_frame_avg' in result:
                        logger.info(f"    SV2000æ¡†æ¶åˆ†æ•°:")
                        logger.info(f"      å¹³å‡: {result['sv_frame_avg']:.3f}")
                        logger.info(f"      å†²çª: {result.get('sv_conflict', 0):.3f}")
                        logger.info(f"      äººæƒ…: {result.get('sv_human', 0):.3f}")
                        logger.info(f"      ç»æµ: {result.get('sv_econ', 0):.3f}")
                        logger.info(f"      é“å¾·: {result.get('sv_moral', 0):.3f}")
                        logger.info(f"      è´£ä»»: {result.get('sv_resp', 0):.3f}")
                    
                    if 'fusion_weights' in result:
                        logger.info(f"    èåˆæƒé‡: {result['fusion_weights']}")
            
            logger.info("ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        
        # ç”Ÿæˆä½¿ç”¨æŒ‡å—
        logger.info("\næ­¥éª¤ 5: ç”Ÿæˆä½¿ç”¨æŒ‡å—")
        logger.info("-" * 50)
        
        usage_guide_path = os.path.join(args.work_dir, "USAGE_GUIDE.md")
        
        guide_content = f"""# è®­ç»ƒç»“æœä½¿ç”¨æŒ‡å—

## è®­ç»ƒä¿¡æ¯

- **æ•°æ®æº**: {args.data_path}
- **è®­ç»ƒæ—¶é—´**: {pd.Timestamp.now()}
- **è®­ç»ƒå‚æ•°**: 
  - è½®æ•°: {args.epochs}
  - æ‰¹å¤§å°: {args.batch_size}
  - å­¦ä¹ ç‡: {args.learning_rate}
  - è®¾å¤‡: {args.device}

## ç”Ÿæˆçš„æ–‡ä»¶

### æ¨¡å‹æ–‡ä»¶
- `models/best_sv2000_model.pt` - è®­ç»ƒå¥½çš„SV2000æ¨¡å‹
- `models/training_report.json` - è¯¦ç»†è®­ç»ƒæŠ¥å‘Š

### ä¼˜åŒ–ç»“æœ
- `optimization/fusion_optimization_results.json` - æƒé‡ä¼˜åŒ–ç»“æœ
- `optimization/fusion_optimization_results_report.md` - ä¼˜åŒ–æŠ¥å‘Š

### æ•°æ®æ–‡ä»¶
- `adapted_training_data.csv` - é€‚é…åçš„è®­ç»ƒæ•°æ®ï¼ˆå¦‚æœè¿›è¡Œäº†é€‚é…ï¼‰

## ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹

```python
from framing_analyzer import FramingAnalyzer
from framing_analyzer.config import create_sv2000_config

# åˆ›å»ºé…ç½®
config = create_sv2000_config()

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
config.sv_framing.pretrained_model_path = "{model_path}"

# åˆå§‹åŒ–åˆ†æå™¨
analyzer = FramingAnalyzer(config)

# åˆ†ææ–‡ç« 
article_text = "Your news article content here..."
result = analyzer.analyze_article(article_text, title="Article Title")

# æŸ¥çœ‹ç»“æœ
print(f"æ¡†æ¶å¼ºåº¦: {{result.framing_intensity:.3f}}")
print(f"SV2000åˆ†æ•°: {{result.sv_frame_avg:.3f}}")
print(f"å„æ¡†æ¶åˆ†æ•°:")
print(f"  å†²çª: {{result.sv_conflict:.3f}}")
print(f"  äººæƒ…: {{result.sv_human:.3f}}")
print(f"  ç»æµ: {{result.sv_econ:.3f}}")
print(f"  é“å¾·: {{result.sv_moral:.3f}}")
print(f"  è´£ä»»: {{result.sv_resp:.3f}}")
```

## ä¸‹ä¸€æ­¥å»ºè®®

1. **è¯„ä¼°æ¨¡å‹æ€§èƒ½**: æŸ¥çœ‹è®­ç»ƒæŠ¥å‘Šä¸­çš„éªŒè¯æŒ‡æ ‡
2. **è°ƒæ•´èåˆæƒé‡**: æ ¹æ®ä¼˜åŒ–ç»“æœè°ƒæ•´æƒé‡é…ç½®
3. **æ‰©å±•æ•°æ®é›†**: ä½¿ç”¨æ›´å¤šæ•°æ®ç»§ç»­è®­ç»ƒ
4. **éƒ¨ç½²åº”ç”¨**: å°†æ¨¡å‹é›†æˆåˆ°ç”Ÿäº§ç¯å¢ƒ

## æ•…éšœæ’é™¤

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š
1. æ£€æŸ¥è®­ç»ƒæŠ¥å‘Šä¸­çš„é”™è¯¯ä¿¡æ¯
2. éªŒè¯æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®
3. ç¡®è®¤æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´
4. å‚è€ƒ `TRAINING_GUIDE.md` è·å–è¯¦ç»†å¸®åŠ©

---
*è®­ç»ƒå®Œæˆæ—¶é—´: {pd.Timestamp.now()}*
"""
        
        with open(usage_guide_path, 'w', encoding='utf-8') as f:
            f.write(guide_content)
        
        logger.info(f"ä½¿ç”¨æŒ‡å—å·²ç”Ÿæˆ: {usage_guide_path}")
        
        # æœ€ç»ˆæ€»ç»“
        logger.info("\n" + "=" * 80)
        logger.info("è®­ç»ƒæµç¨‹å®Œæˆï¼")
        logger.info("=" * 80)
        logger.info(f"ğŸ“ å·¥ä½œç›®å½•: {args.work_dir}")
        logger.info(f"ğŸ“„ ä½¿ç”¨æŒ‡å—: {usage_guide_path}")
        
        if os.path.exists(model_path):
            logger.info(f"ğŸ¤– è®­ç»ƒæ¨¡å‹: {model_path}")
        
        optimization_results = os.path.join(args.work_dir, "optimization", "fusion_optimization_results.json")
        if os.path.exists(optimization_results):
            logger.info(f"âš–ï¸  æƒé‡ä¼˜åŒ–: {optimization_results}")
        
        logger.info("\nâœ… ç°åœ¨å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„SV2000æ¨¡å‹è¿›è¡Œæ–°é—»æ¡†æ¶åˆ†æï¼")
        
    except Exception as e:
        logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    # å¯¼å…¥pandasç”¨äºæ—¶é—´æˆ³
    import pandas as pd
    main()
