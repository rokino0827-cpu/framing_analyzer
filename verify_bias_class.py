#!/usr/bin/env python3
"""
éªŒè¯bias_detectoræ¨¡å‹çš„biasç±»åˆ«ç´¢å¼•
ä½¿ç”¨å¯¹ç…§å¥ç¡®å®šå“ªä¸ªç´¢å¼•å¯¹åº”biasç±»åˆ«
"""

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np

def verify_bias_class_index(model_path="bias_detector_data"):
    """éªŒè¯biasç±»åˆ«ç´¢å¼•"""
    
    print("ğŸ” æ­£åœ¨éªŒè¯biasç±»åˆ«ç´¢å¼•...")
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
    
    # è®¾å¤‡é€‰æ‹©
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
        model = AutoModelForSequenceClassification.from_pretrained(model_path, local_files_only=True)
        model = model.to(device).eval()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "This is a factual report about the event.",  # åä¸­æ€§
        "Those people are disgusting and should be punished.",  # æ˜æ˜¾åè§/æ”»å‡»æ€§
    ]
    
    print("\nğŸ“ æµ‹è¯•æ–‡æœ¬:")
    for i, text in enumerate(test_texts):
        print(f"  {i+1}. {text}")
    
    # æ¨ç†
    print("\nğŸ§  è¿›è¡Œæ¨ç†...")
    inputs = tokenizer(test_texts, padding=True, truncation=True, return_tensors="pt").to(device)
    
    with torch.inference_mode():
        logits = model(**inputs).logits
        probs = torch.softmax(logits, dim=-1).cpu().numpy()
    
    # åˆ†æç»“æœ
    print("\nğŸ“Š åˆ†æç»“æœ:")
    print(f"æ¨¡å‹é…ç½®:")
    print(f"  num_labels: {model.config.num_labels}")
    print(f"  id2label: {getattr(model.config, 'id2label', 'N/A')}")
    print(f"  label2id: {getattr(model.config, 'label2id', 'N/A')}")
    
    print(f"\næ¦‚ç‡åˆ†å¸ƒ:")
    print(f"  ä¸­æ€§æ–‡æœ¬: {probs[0]}")
    print(f"  åè§æ–‡æœ¬: {probs[1]}")
    
    # è®¡ç®—å·®å€¼
    delta = probs[1] - probs[0]
    print(f"\nå·®å€¼ (åè§-ä¸­æ€§): {delta}")
    
    # æ¨èé…ç½®
    print("\nğŸ’¡ æ¨èé…ç½®:")
    
    if model.config.num_labels == 2:
        # æ‰¾å‡ºåœ¨åè§æ–‡æœ¬ä¸­æ¦‚ç‡æå‡æœ€å¤§çš„ç´¢å¼•
        max_increase_idx = np.argmax(delta)
        max_increase = delta[max_increase_idx]
        
        if max_increase > 0.1:  # æ˜¾è‘—å·®å¼‚
            print(f"âœ… æ¨èä½¿ç”¨ bias_class_index = {max_increase_idx}")
            print(f"   ç†ç”±: åœ¨åè§æ–‡æœ¬ä¸­ï¼Œç´¢å¼•{max_increase_idx}çš„æ¦‚ç‡æå‡äº† {max_increase:.3f}")
            
            print(f"\nğŸ”§ é…ç½®æ–¹æ³•:")
            print(f"   æ–¹æ³•1 - åœ¨ä»£ç ä¸­è®¾ç½®:")
            print(f"   config = AnalyzerConfig()")
            print(f"   config.teacher.bias_class_index = {max_increase_idx}")
            
            print(f"\n   æ–¹æ³•2 - åœ¨JSONé…ç½®æ–‡ä»¶ä¸­è®¾ç½®:")
            print(f"   \"teacher\": {{")
            print(f"     \"bias_class_index\": {max_increase_idx}")
            print(f"   }}")
            
            return {
                'recommended_index': int(max_increase_idx),
                'confidence': float(max_increase),
                'probabilities': probs.tolist(),
                'delta': delta.tolist()
            }
        else:
            print("âš ï¸  ä¸¤ä¸ªç±»åˆ«çš„å·®å¼‚ä¸å¤Ÿæ˜æ˜¾ï¼Œå¯èƒ½éœ€è¦æ›´æ˜ç¡®çš„æµ‹è¯•æ–‡æœ¬")
            print(f"   æœ€å¤§å·®å¼‚: {max_increase:.3f} (å»ºè®® > 0.1)")
            return None
    else:
        print(f"âš ï¸  æ¨¡å‹æœ‰ {model.config.num_labels} ä¸ªç±»åˆ«ï¼Œéœ€è¦æ‰‹åŠ¨åˆ†æ")
        return None

if __name__ == "__main__":
    result = verify_bias_class_index()
    
    if result:
        print(f"\nğŸ‰ éªŒè¯å®Œæˆï¼æ¨èä½¿ç”¨ bias_class_index = {result['recommended_index']}")
    else:
        print(f"\nâŒ æ— æ³•ç¡®å®šæ¨èé…ç½®ï¼Œè¯·æ‰‹åŠ¨åˆ†æç»“æœ")