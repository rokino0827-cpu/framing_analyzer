#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - ç”¨äºæ—¥å¸¸å¼€å‘å’Œè°ƒè¯•

ç”¨æ³•ï¼š
    PYTHONPATH="/root/autodl-tmp" python framing_analyzer/quick_test.py
"""

import sys
import time
import logging
from pathlib import Path

import pandas as pd
import numpy as np

# è®¾ç½®è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(PROJECT_ROOT.parent))

from framing_analyzer import (
    AnalyzerConfig, 
    create_analyzer,
    verify_bias_class_index
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def quick_test():
    """å¿«é€Ÿæµ‹è¯•ä¸»è¦åŠŸèƒ½"""
    
    print("ğŸš€ Starting quick test...")
    
    # 1. éªŒè¯bias_class_index
    print("\n1ï¸âƒ£  Verifying bias class index...")
    try:
        result = verify_bias_class_index()
        if result and 'config_suggestion' in result:
            bias_index = result['config_suggestion']['bias_class_index']
            print(f"âœ… Recommended bias_class_index: {bias_index}")
        else:
            bias_index = 1
            print(f"âš ï¸  Using default bias_class_index: {bias_index}")
    except Exception as e:
        print(f"âš ï¸  Verification failed, using default: {e}")
        bias_index = 1
    
    # 2. åˆ›å»ºé…ç½®
    print("\n2ï¸âƒ£  Creating configuration...")
    config = AnalyzerConfig()
    config.teacher.bias_class_index = bias_index
    config.teacher.model_local_path = str(PROJECT_ROOT / "bias_detector_data")
    config.output.output_dir = str(PROJECT_ROOT / "results/quick_test")
    print("âœ… Configuration created")
    
    # 3. æµ‹è¯•æ•°æ®
    print("\n3ï¸âƒ£  Loading test data...")
    data_path = PROJECT_ROOT / "data/all-the-news-2-1_2025-window_bias_scored_balanced_500_clean.csv"
    
    if data_path.exists():
        df = pd.read_csv(data_path, encoding="utf-8")
        df = df[df["content"].notna() & df["title"].notna()].head(5)
        
        articles = []
        for idx, row in df.iterrows():
            articles.append({
                "id": f"test_{idx}",
                "title": str(row["title"]),
                "content": str(row["content"])
            })
        print(f"âœ… Loaded {len(articles)} test articles")
    else:
        # ä½¿ç”¨å†…ç½®æµ‹è¯•æ•°æ®
        articles = [
            {
                "id": "test_1",
                "title": "Economic Policy Update",
                "content": "The government announced new economic policies yesterday. These measures are expected to impact various sectors of the economy. Officials stated that the implementation will begin next quarter."
            },
            {
                "id": "test_2", 
                "title": "Technology Innovation Report",
                "content": "A new breakthrough in artificial intelligence has been reported by researchers. The technology promises to revolutionize how we process information. Industry experts are optimistic about its potential applications."
            },
            {
                "id": "test_3",
                "title": "Climate Change Discussion",
                "content": "Scientists continue to study the effects of climate change on global weather patterns. Recent data shows significant changes in temperature and precipitation. Policymakers are considering various response strategies."
            }
        ]
        print(f"âœ… Using {len(articles)} built-in test articles")
    
    # 4. åŸºç¡€åˆ†ææµ‹è¯•
    print("\n4ï¸âƒ£  Testing basic analysis...")
    start_time = time.time()
    
    try:
        analyzer = create_analyzer(config)
        results = analyzer.analyze_batch(articles)
        
        analysis_time = time.time() - start_time
        
        print(f"âœ… Analysis completed in {analysis_time:.2f}s")
        print(f"ğŸ“Š Processed {len(results['results'])} articles")
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦ - ä¿®å¤å­—æ®µè®¿é—®
        if 'results' in results and results['results']:
            framing_intensities = []
            for result_dict in results['results']:
                if isinstance(result_dict, dict):
                    framing_intensities.append(result_dict.get('framing_intensity', 0.0))
                else:
                    framing_intensities.append(getattr(result_dict, 'framing_intensity', 0.0))
            
            print(f"ğŸ“ˆ Framing intensities: {[f'{s:.3f}' for s in framing_intensities]}")
            print(f"ğŸ“Š Average intensity: {np.mean(framing_intensities):.3f}")
            
            # æ˜¾ç¤ºç¬¬ä¸€ç¯‡æ–‡ç« çš„è¯¦ç»†ç»“æœ
            first_result = results['results'][0]
            if isinstance(first_result, dict):
                article_id = first_result.get('id', 'unknown')
                framing_intensity = first_result.get('framing_intensity', 0.0)
                pseudo_label = first_result.get('pseudo_label', 'uncertain')
                evidence_count = len(first_result.get('evidence', []))
            else:
                article_id = getattr(first_result, 'id', 'unknown')
                framing_intensity = getattr(first_result, 'framing_intensity', 0.0)
                pseudo_label = getattr(first_result, 'pseudo_label', 'uncertain')
                evidence_count = len(getattr(first_result, 'evidence', []))
            
            print(f"\nğŸ“„ Sample result (Article: {article_id}):")
            print(f"   Framing Intensity: {framing_intensity:.3f}")
            print(f"   Pseudo Label: {pseudo_label}")
            print(f"   Evidence Count: {evidence_count}")
        else:
            raise ValueError("No results returned from analyzer")
        
    except Exception as e:
        print(f"âŒ Analysis failed: {e}")
        return False
    
    # 5. çœç•¥æ£€æµ‹æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
    print("\n5ï¸âƒ£  Testing omission detection (optional)...")
    try:
        omission_config = config
        omission_config.omission.enabled = True
        
        omission_analyzer = create_analyzer(omission_config)
        omission_results = omission_analyzer.analyze_batch(articles[:2])  # åªæµ‹è¯•2ç¯‡
        
        omission_count = 0
        if 'results' in omission_results and omission_results['results']:
            for result_dict in omission_results['results']:
                if isinstance(result_dict, dict):
                    if result_dict.get('omission_score') is not None:
                        omission_count += 1
                else:
                    if hasattr(result_dict, 'omission_score') and result_dict.omission_score is not None:
                        omission_count += 1
        
        total_results = len(omission_results['results']) if omission_results and 'results' in omission_results else 0
        
        print(f"âœ… Omission detection test completed")
        print(f"ğŸ“Š Articles with omissions: {omission_count}/{total_results}")
        
    except Exception as e:
        print(f"âš ï¸  Omission detection test failed: {e}")
    
    print("\nğŸ‰ Quick test completed successfully!")
    print("\nğŸ’¡ To run comprehensive test:")
    print("   python framing_analyzer/comprehensive_test.py --sample 20")
    
    return True

if __name__ == "__main__":
    success = quick_test()
    sys.exit(0 if success else 1)
